# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18V0-Pkvw7HnTArRlKBz8Vd4-Oc5laMux
"""

import scipy.io as io
import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
import matplotlib.pyplot as plt
from google.colab import drive

"""Mounting google drive"""

drive.mount('/content/drive')

"""Load the training and testing dataset"""

training_dataset = io.loadmat('/content/drive/MyDrive/train_32x32.mat')
testing_dataset = io.loadmat('/content/drive/MyDrive/test_32x32.mat')
trX = training_dataset['X']
trY = training_dataset['y']
tsX = testing_dataset['X']
tsY = testing_dataset['y']

"""Initialize the parameters"""

batch_size = 64
learning_rate = 0.01
epochs = 20
rows = 32
cols = 32
channels = 3
num_classes = 10
kernel_size = (5, 5)
pool_size = (2, 2)

"""Normalize the input and get it in the range of 0-1, encode the labels using one-hot vector encoding"""

trX = trX / 255
tsX = tsX / 255

trY = keras.utils.to_categorical(trY, num_classes)
tsY = keras.utils.to_categorical(tsY, num_classes)

"""Build the CNN model using the given architecture"""

model = Sequential()
# Convolutional layer with 64 output feature maps, ReLU activation, 5*5 kernel size and stride 1*1.
model.add(Conv2D(64, kernel_size = kernel_size, activation = 'relu', input_shape = (rows, cols, channels), padding = 'same'))
# Max pooling with 2*2 kernel size and stride 2*2.
model.add(MaxPooling2D(pool_size = pool_size, strides = (2, 2)))
# Convolutional layer with 64 output feature maps, ReLU activation, 5*5 kernel size and stride 1*1.
model.add(Conv2D(64, kernel_size = kernel_size, activation = 'relu', padding = 'same'))
# Max pooling with 2*2 kernel size and stride 2*2.
model.add(MaxPooling2D(pool_size = pool_size, strides = (2, 2)))
# Convolutional layer with 128 output feature maps, ReLU activation, 5*5 kernel size and stride 1*1.
model.add(Conv2D(128, kernel_size = kernel_size, activation = 'relu', padding = 'same'))
# Flatten the output obtained by the last convolutional layer
model.add(Flatten())
#	Fully connected layer with 3072 nodes (output size), ReLU activation.
model.add(Dense(3072, activation='relu'))
# Fully connected layer with 2048 nodes, ReLU activation.
model.add(Dense(2048, activation='relu'))
#	Fully connected layer with 10 nodes (corresponding to 10 classes), SoftMax activation.
model.add(Dense(10, activation='softmax'))

"""Train the model using SGD optimizer"""

model.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.SGD(learning_rate = learning_rate), metrics = ['accuracy'])
history = model.fit(trX, trY, batch_size = batch_size, epochs = epochs, validation_data = (tsX, tsY))

"""Test the model and print the loss and accuracy"""

score = model.evaluate(tsX, tsY)
print('Test loss: ', score[0])
print('Test accuracy: ', score[1])

"""Plot the Loss vs Epochs and Accuracy vs Epochs graphs"""

epochs_range = range(1, epochs + 1)

plt.figure(1)
loss_train = history.history['loss']
loss_test = history.history['val_loss']
plt.plot(epochs_range, loss_train, label = 'Training loss')
plt.plot(epochs_range, loss_test, label = 'Testing loss')
plt.title('Training and Testing loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.figure(2)
accuracy_train = history.history['accuracy']
accuracy_test = history.history['val_accuracy']
plt.plot(epochs_range, accuracy_train, label = 'Training accuracy')
plt.plot(epochs_range, accuracy_test, label = 'Testing accuracy')
plt.title('Training and Testing accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()